{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n",
      "/var/folders/6n/b_zkz2ns3_l02s3g4lnlklxr0000gq/T/ipykernel_52474/458879225.py:13: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir=config_dir):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RosaLightningModule(\n",
      "  (model): RosaSingleModel(\n",
      "    (main): Sequential(\n",
      "      (layer_norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "      (input_embed): Identity()\n",
      "      (feed_forward): Identity()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (expression_head): ProjectionExpressionHead(\n",
      "        (model): Sequential(\n",
      "          (projection): Linear(in_features=3072, out_features=369, bias=True)\n",
      "          (activation): Softplus(beta=1, threshold=20)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /Users/nsofroniew/Documents/GitHub/rosa/notebooks/lightning_logs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc656c94828346f49eaa2ac1f3352a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 369 × 19431\n",
       "    obs: 'dataset_id', 'cell_type', 'cell_type_ontology_term_id', 'development_stage', 'development_stage_ontology_term_id', 'disease', 'disease_ontology_term_id', 'donor_id', 'is_primary_data', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'sex', 'sex_ontology_term_id', 'suspension_type', 'label', 'sample', 'n_genes', 'train', 'marker_gene', 'marker_feature_name'\n",
       "    var: 'soma_joinid', 'feature_name', 'feature_length', 'column_1', 'column_2', 'column_3', 'column_4', 'external_gene_name', 'gene_biotype', 'train', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'dendrogram_label', 'hvg', 'log1p', 'obs_embedding_pca', 'preprocessing', 'rank_genes_groups', 'var_embedding_pca'\n",
       "    obsm: 'bin_edges', 'embedding'\n",
       "    varm: 'embedding', 'embedding_pca'\n",
       "    layers: 'binned', 'counts', 'log1p', 'normalized_counts', 'prediction'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from glob import  glob\n",
    "# from rosa import  predict\n",
    "from rosa.data import create_io_paths, RosaDataModule\n",
    "from rosa.modeling.modules import RosaLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/nsofroniew/Documents/data/rosa/outputs/2023-02-12/21-58-13\"\n",
    "config_dir = BASE_DIR + \"/.hydra\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_dir):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=OmegaConf.load(config_dir + \"/overrides.yaml\"))\n",
    "\n",
    "    chkpts = BASE_DIR + \"/checkpoints/*.ckpt\"\n",
    "    chkpt = glob(chkpts)[1]\n",
    "\n",
    "    _, output_path = create_io_paths(config.paths)\n",
    "\n",
    "    # Create Data Module\n",
    "    rdm = RosaDataModule(\n",
    "        output_path,\n",
    "        config=config.data_module,\n",
    "    )\n",
    "    rdm.setup()\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    rlm = RosaLightningModule.load_from_checkpoint(\n",
    "        chkpt,\n",
    "        in_dim=rdm.len_input,\n",
    "        out_dim=rdm.len_target,\n",
    "        config=config.module,\n",
    "    )\n",
    "    print(rlm)\n",
    "\n",
    "    trainer = Trainer()\n",
    "    predictions = trainer.predict(rlm, rdm)\n",
    "    rdm.predict_dataset.predict(predictions)\n",
    "    adata = rdm.predict_dataset.adata\n",
    "    # adata = predict(config, chkpt)\n",
    "\n",
    "display(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cells = adata.obs['train']\n",
    "train_genes = adata.var['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from captum library\n",
    "from captum.attr import IntegratedGradients, InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(rlm)\n",
    "ixg = InputXGradient(rlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor = rdm.predict_dataset[:][0]\n",
    "target_tensor = rdm.predict_dataset[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19431, 369])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlm.forward(test_input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "# results_shape = tuple((len(rdm.predict_dataset), rdm.len_target, r) for r in rdm.len_input) # rdm.len_target\n",
    "results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.open(f'data/gene_attribution.zarr', mode='w', shape=results_shape, chunks=(None, 1, None), dtype=np.float32)\n",
    "\n",
    "ind = 0\n",
    "dl = rdm.predict_dataloader(batch_size=1)\n",
    "for attribution in tqdm(iter(rlm.explain_iter(dl, ixg)), total=len(dl)):\n",
    "    # z[ind:ind+len(attribution), :, :] = attribution.detach().numpy() # for cell\n",
    "    z[:, ind:ind+len(attribution), :] = attribution.detach().numpy().swapaxes(0, 1) # for gene\n",
    "    ind += len(attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "z = da.from_zarr(f'data/gene_attribution.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_avg = np.asarray(da.abs(z).mean(axis=(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(z_avg)), np.sort(z_avg)[::-1]);\n",
    "plt.xlabel('embed dim');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_avg_cells = np.asarray(da.abs(z).mean(axis=(0,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(z_avg)[::-1]\n",
    "z_avg_cells = z_avg_cells[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_avg_cells.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(z_avg_cells[:100, :100], vmax=.1);\n",
    "plt.xlabel('n emb');\n",
    "plt.ylabel('target gene');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(z_avg_cells[:100, :100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to full enformer based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import Enformer\n",
    "\n",
    "\n",
    "MODEL_PT = \"EleutherAI/enformer-official-rough\"\n",
    "SEQ_EMBED_DIM = 896\n",
    "EMBED_DIM = 3072\n",
    "TSS = int(SEQ_EMBED_DIM // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class FullVarModel(nn.Module):\n",
    "    def __init__(self, rlm):\n",
    "        super(FullVarModel, self).__init__()\n",
    "        self.enformer = Enformer.from_pretrained(MODEL_PT, output_heads=dict(), use_checkpointing=False)\n",
    "        self.model = rlm.model\n",
    "        self.tss = TSS\n",
    "\n",
    "    def forward(self, seq):\n",
    "        _, embeddings = self.enformer(seq, return_embeddings=True)\n",
    "        x = embeddings[:, self.tss]\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at EleutherAI/enformer-official-rough were not used when initializing Enformer: ['_heads.mouse.0.weight', '_heads.mouse.0.bias', '_heads.human.0.bias', '_heads.human.0.weight']\n",
      "- This IS expected if you are initializing Enformer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Enformer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = FullVarModel(rlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PT = \"/Users/nsofroniew/Documents/data/multiomics/enformer\"\n",
    "FASTA_PT = BASE_PT + \"/Homo_sapiens.GRCh38.dna.toplevel.fa\"\n",
    "\n",
    "config.data_module.data.var_input = FASTA_PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Module\n",
    "rdm = RosaDataModule(\n",
    "    output_path,\n",
    "    config=config.data_module,\n",
    ")\n",
    "rdm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([196608, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm.predict_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(rdm.predict_dataset[0][0].unsqueeze_(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 369])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzarr\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(np\u001b[39m.\u001b[39mlogical_not(rdm\u001b[39m.\u001b[39mtest_dataset\u001b[39m.\u001b[39madata\u001b[39m.\u001b[39mobs[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]))[\u001b[39m0\u001b[39m][:\u001b[39m2\u001b[39m]\n\u001b[1;32m      4\u001b[0m results_shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(test_indices), \u001b[39mlen\u001b[39m(rdm\u001b[39m.\u001b[39mtest_dataset), rdm\u001b[39m.\u001b[39mlen_input)\n\u001b[1;32m      5\u001b[0m z \u001b[39m=\u001b[39m zarr\u001b[39m.\u001b[39mopen(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/gene_attribution_full.zarr\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, shape\u001b[39m=\u001b[39mresults_shape, chunks\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "test_indices = np.where(np.logical_not(rdm.test_dataset.adata.obs['train']))[0]\n",
    "results_shape = (len(test_indices), len(rdm.test_dataset), rdm.len_input)\n",
    "z = zarr.open(f'data/gene_attribution_full.zarr', mode='w', shape=results_shape, chunks=(None, 1, None), dtype=np.float32)\n",
    "dl = rdm.test_dataloader(batch_size=1)\n",
    "\n",
    "ixg = InputXGradient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 5792, 196608)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441.836371968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.nbytes / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5792 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "ind = 0\n",
    "for attribution in tqdm(iter(rlm.explain_iter(dl, ixg, indices=test_indices)), total=len(dl)):\n",
    "    z[:, ind:ind+len(attribution), :] = attribution.detach().numpy() # for gene\n",
    "    ind += len(attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "full_attrs_G_ds = convolve(full_attrs_G, (np.ones(128)/128)[np.newaxis, np.newaxis, :])[:, :, ::128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_ds.shape[2]), np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_ds.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)))[::-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import seq_indices_to_one_hot\n",
    "\n",
    "test_input_tensor = torch.stack([ds[i][1] for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(model)\n",
    "ig = InputXGradient(model)\n",
    "\n",
    "full_attrs_G = []\n",
    "for targ in tqdm(range(3)):\n",
    "    test_input_tensor.requires_grad_()\n",
    "    attr = ig.attribute(test_input_tensor, target=targ)\n",
    "    # sum across all nucleotides (note value 0 for non used value)\n",
    "    attr = attr.sum(dim=-1)\n",
    "    # pool across sliding window\n",
    "    # attr = torch.nn.functional.avg_pool1d(attr, 128)\n",
    "    attr = attr.detach().numpy()\n",
    "    full_attrs_G.append(attr)\n",
    "full_attrs_G = np.stack(full_attrs_G, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(0, 1)), lw=0.05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(1,))[0] / np.mean(np.abs(full_attrs_G), axis=(1,))[0].max(), lw=0.05);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(1,))[1] / np.mean(np.abs(full_attrs_G), axis=(1,))[1].max(), lw=0.05, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G_ds.shape[2]), np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)), lw=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.sort(np.mean(np.abs(full_attrs_G), axis=(0, 1)))[::-1], lw=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = slice(66_300, 66_800)\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 0][keep], lw=0.5);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 1][keep], lw=0.5, alpha=0.5);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 2][keep], lw=0.5, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "196608 * 20_000 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modisco.visualization import viz_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights((full_attrs_G[0, 0, :, np.newaxis] * test_input_tensor[0].detach().numpy())[98304-100:98304+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "196608 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G.shape[2]), np.sort(np.mean(np.abs(full_attrs_G), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train = full_attrs_G[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_test = full_attrs_G[:, np.logical_not(adata.var['train'][:200])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(280), np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);\n",
    "plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attr = np.mean(np.sum(full_attrs_G_train, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_attr, diag, '.');\n",
    "plt.xlabel('total attribution');\n",
    "plt.ylabel('mean self attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, total_attr, '.');\n",
    "plt.xlabel('mean expression');\n",
    "plt.ylabel('total attribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_test[keep]), axis=0)\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_norm = full_attrs_G / np.expand_dims(np.sum(full_attrs_G, axis=-1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train_norm = full_attrs_G_norm[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train_norm.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_train_norm[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]\n",
    "\n",
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = full_attrs_G_r[10, :, :140]\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(full_attrs_G, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(test_input_tensor) - model(torch.zeros_like(test_input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(X[:, :100].detach().numpy() - np.sum(full_attrs_G, axis=-1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.zeros_like(test_input_tensor)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model(torch.zeros_like(test_input_tensor))[0].detach().numpy(), bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = np.cumsum(np.mean(np.abs(full_attrs), axis=(0, 2)))\n",
    "fa = fa / fa[-1]\n",
    "\n",
    "plt.plot(np.arange(256), fa);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('cumulative mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[:256, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlm.fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.utils import score_predictions, plot_expression_and_correlation, plot_marker_gene_heatmap\n",
    "\n",
    "\n",
    "adata_test, results = score_predictions(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_expression_and_correlation(adata_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "marker_genes = adata_test.var[adata_test.var['highly_variable']]['feature_name'].values\n",
    "np.random.seed(42)\n",
    "marker_genes = np.random.choice(marker_genes, 50)\n",
    "\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = adata_test.obs.set_index('label').to_dict()['marker_feature_name']\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c78ef6e1dc348573331f887aa1706c62aacac0373dba7ce1cc27999251039c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
