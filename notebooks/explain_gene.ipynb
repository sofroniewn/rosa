{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n",
      "/var/folders/6n/b_zkz2ns3_l02s3g4lnlklxr0000gq/T/ipykernel_97488/458879225.py:13: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir=config_dir):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RosaLightningModule(\n",
      "  (model): RosaSingleModel(\n",
      "    (main): Sequential(\n",
      "      (layer_norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "      (input_embed): Identity()\n",
      "      (feed_forward): Identity()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (expression_head): ProjectionExpressionHead(\n",
      "        (model): Sequential(\n",
      "          (projection): Linear(in_features=3072, out_features=369, bias=True)\n",
      "          (activation): Softplus(beta=1, threshold=20)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /Users/nsofroniew/Documents/GitHub/rosa/notebooks/lightning_logs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af51fd43f31a497a8a10fb6d6c43b1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 369 × 19431\n",
       "    obs: 'dataset_id', 'cell_type', 'cell_type_ontology_term_id', 'development_stage', 'development_stage_ontology_term_id', 'disease', 'disease_ontology_term_id', 'donor_id', 'is_primary_data', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'sex', 'sex_ontology_term_id', 'suspension_type', 'label', 'sample', 'n_genes', 'train', 'marker_gene', 'marker_feature_name'\n",
       "    var: 'soma_joinid', 'feature_name', 'feature_length', 'column_1', 'column_2', 'column_3', 'column_4', 'external_gene_name', 'gene_biotype', 'train', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'dendrogram_label', 'hvg', 'log1p', 'obs_embedding_pca', 'preprocessing', 'rank_genes_groups', 'var_embedding_pca'\n",
       "    obsm: 'bin_edges', 'embedding'\n",
       "    varm: 'embedding', 'embedding_pca'\n",
       "    layers: 'binned', 'counts', 'log1p', 'normalized_counts', 'prediction'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from glob import  glob\n",
    "# from rosa import  predict\n",
    "from rosa.data import create_io_paths, RosaDataModule\n",
    "from rosa.modeling.modules import RosaLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/nsofroniew/Documents/data/rosa/outputs/2023-02-12/21-58-13\"\n",
    "config_dir = BASE_DIR + \"/.hydra\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_dir):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=OmegaConf.load(config_dir + \"/overrides.yaml\"))\n",
    "\n",
    "    chkpts = BASE_DIR + \"/checkpoints/*.ckpt\"\n",
    "    chkpt = glob(chkpts)[1]\n",
    "\n",
    "    _, output_path = create_io_paths(config.paths)\n",
    "\n",
    "    # Create Data Module\n",
    "    rdm = RosaDataModule(\n",
    "        output_path,\n",
    "        config=config.data_module,\n",
    "    )\n",
    "    rdm.setup()\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    rlm = RosaLightningModule.load_from_checkpoint(\n",
    "        chkpt,\n",
    "        in_dim=rdm.len_input,\n",
    "        out_dim=rdm.len_target,\n",
    "        config=config.module,\n",
    "    )\n",
    "    print(rlm)\n",
    "\n",
    "    trainer = Trainer()\n",
    "    predictions = trainer.predict(rlm, rdm)\n",
    "    rdm.predict_dataset.predict(predictions)\n",
    "    adata = rdm.predict_dataset.adata\n",
    "    # adata = predict(config, chkpt)\n",
    "\n",
    "display(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cells = adata.obs['train']\n",
    "train_genes = adata.var['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from captum library\n",
    "from captum.attr import IntegratedGradients, InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(rlm)\n",
    "ixg = InputXGradient(rlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor = rdm.predict_dataset[:][0]\n",
    "target_tensor = rdm.predict_dataset[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19431, 369])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlm.forward(test_input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.20s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.26s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.24s/it]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.67s/it]\n",
      "                                             \r"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "results_shape = (len(rdm.predict_dataset), 50, rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.zeros(results_shape, chunks=(1, None, None), dtype=np.float32)\n",
    "\n",
    "ind = 0\n",
    "for x, y in tqdm(iter(rdm.predict_dataloader(batch_size=1)), leave=False):\n",
    "    for target in tqdm(range(2)):\n",
    "        x.requires_grad_()\n",
    "        attribution = ixg.attribute(x, target=target)\n",
    "        attribution = attribution.detach().numpy()\n",
    "        # z[target, ind:ind+len(x), :] = attribution # for gene dataset\n",
    "        z[ind:ind+len(x), target, :] = attribution # for cell dataset\n",
    "        #### for joint have to do something more clever ...... maybe swap iterators\n",
    "    ind += len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array (19431, 50, 3072) float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs = []\n",
    "n_targets = 20 #target_tensor.shape[1]\n",
    "for targ in tqdm(range(n_targets)):\n",
    "    test_input_tensor.requires_grad_()\n",
    "    attr = ig.attribute(test_input_tensor, target=targ)\n",
    "    attr = attr.detach().numpy()\n",
    "    full_attrs.append(attr)\n",
    "full_attrs = np.stack(full_attrs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), full_attrs[0, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), np.mean(np.abs(full_attrs), axis=(0, 1)));\n",
    "plt.xlabel('n emb');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), np.sort(np.mean(np.abs(full_attrs), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('n emb');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs), axis=(0,))[:, :85]);\n",
    "plt.xlabel('n emb');\n",
    "plt.ylabel('target gene');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(np.mean(np.abs(full_attrs), axis=0)[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switch to full enformer based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import Enformer\n",
    "\n",
    "\n",
    "MODEL_PT = \"EleutherAI/enformer-official-rough\"\n",
    "SEQ_EMBED_DIM = 896\n",
    "EMBED_DIM = 3072\n",
    "TSS = int(SEQ_EMBED_DIM // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, rlm):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.enformer = Enformer.from_pretrained(MODEL_PT, output_heads=dict(), use_checkpointing=False)\n",
    "        self.model = rlm.model\n",
    "        self.tss = TSS\n",
    "\n",
    "    def forward(self, seq):\n",
    "        _, embeddings = self.enformer(seq, return_embeddings=True)\n",
    "        x = embeddings[:, self.tss]\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel(rlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import seq_indices_to_one_hot\n",
    "\n",
    "test_input_tensor = torch.randint(0, 5, (1, 196_608)) # for ACGTN, in that order (-1 for padding)\n",
    "test_input_tensor = seq_indices_to_one_hot(test_input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(model)\n",
    "ig = InputXGradient(model)\n",
    "\n",
    "full_attrs_G = []\n",
    "for targ in tqdm(range(3)):\n",
    "    test_input_tensor.requires_grad_()\n",
    "    attr = ig.attribute(test_input_tensor, target=targ)\n",
    "    # sum across all nucleotides (note value 0 for non used value)\n",
    "    attr = attr.sum(dim=-1)\n",
    "    # pool across sliding window\n",
    "    # attr = torch.nn.functional.avg_pool1d(attr, 128)\n",
    "    attr = attr.detach().numpy()\n",
    "    full_attrs_G.append(attr)\n",
    "full_attrs_G = np.stack(full_attrs_G, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "full_attrs_G_ds = convolve(full_attrs_G, (np.ones(128)/128)[np.newaxis, np.newaxis, :])[:, :, ::128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_ds.shape[2]), np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_ds.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)))[::-1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import GenomeIntervalDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BASE_PT = \"/Users/nsofroniew/Documents/data/multiomics/enformer\"\n",
    "\n",
    "FASTA_PT = BASE_PT + \"/Homo_sapiens.GRCh38.dna.toplevel.fa\"\n",
    "GENE_INTERVALS_PT = BASE_PT + \"/Homo_sapiens.GRCh38.genes.bed\"\n",
    "EMBEDDING_PT = BASE_PT + \"/Homo_sapiens.GRCh38.genes.enformer_embeddings.zarr\"\n",
    "EMBEDDING_PT_TSS = BASE_PT + \"/Homo_sapiens.GRCh38.genes.enformer_embeddings_tss.zarr\"\n",
    "MODEL_PT = \"EleutherAI/enformer-official-rough\"\n",
    "\n",
    "# print(\"Converting fasta file\")\n",
    "# pyfaidx.Faidx(FASTA_PT)\n",
    "# print(\"Fasta file done\")\n",
    "\n",
    "# model = Enformer.from_pretrained(MODEL_PT, output_heads=dict(), use_checkpointing = False)\n",
    "# model.to(DEVICE)\n",
    "\n",
    "class MyGenomeIntervalDataset(GenomeIntervalDataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyGenomeIntervalDataset, self).__init__(**kwargs)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        item = super().__getitem__(ind)\n",
    "        label = self.df.row(ind)[4]\n",
    "        return label, item\n",
    "\n",
    "\n",
    "ds = MyGenomeIntervalDataset(\n",
    "    bed_file=GENE_INTERVALS_PT,  # bed file - columns 0, 1, 2 must be <chromosome>, <start position>, <end position>\n",
    "    fasta_file=FASTA_PT,  # path to fasta file\n",
    "    return_seq_indices=False,  # return nucleotide indices (ACGTN) or one hot encodings\n",
    "    rc_aug=False,\n",
    ")\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0) # type: DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import seq_indices_to_one_hot\n",
    "\n",
    "test_input_tensor = torch.stack([ds[i][1] for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(model)\n",
    "ig = InputXGradient(model)\n",
    "\n",
    "full_attrs_G = []\n",
    "for targ in tqdm(range(3)):\n",
    "    test_input_tensor.requires_grad_()\n",
    "    attr = ig.attribute(test_input_tensor, target=targ)\n",
    "    # sum across all nucleotides (note value 0 for non used value)\n",
    "    attr = attr.sum(dim=-1)\n",
    "    # pool across sliding window\n",
    "    # attr = torch.nn.functional.avg_pool1d(attr, 128)\n",
    "    attr = attr.detach().numpy()\n",
    "    full_attrs_G.append(attr)\n",
    "full_attrs_G = np.stack(full_attrs_G, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(0, 1)), lw=0.05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(1,))[0] / np.mean(np.abs(full_attrs_G), axis=(1,))[0].max(), lw=0.05);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.mean(np.abs(full_attrs_G), axis=(1,))[1] / np.mean(np.abs(full_attrs_G), axis=(1,))[1].max(), lw=0.05, alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G_ds.shape[2]), np.mean(np.abs(full_attrs_G_ds), axis=(0, 1)), lw=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(full_attrs_G.shape[2]), np.sort(np.mean(np.abs(full_attrs_G), axis=(0, 1)))[::-1], lw=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = slice(66_300, 66_800)\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 0][keep], lw=0.5);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 1][keep], lw=0.5, alpha=0.5);\n",
    "plt.plot(np.arange(full_attrs_G.shape[2])[keep], np.abs(full_attrs_G)[0, 2][keep], lw=0.5, alpha=0.25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "196608 * 20_000 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modisco.visualization import viz_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_sequence.plot_weights((full_attrs_G[0, 0, :, np.newaxis] * test_input_tensor[0].detach().numpy())[98304-100:98304+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "196608 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G.shape[2]), np.sort(np.mean(np.abs(full_attrs_G), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train = full_attrs_G[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_test = full_attrs_G[:, np.logical_not(adata.var['train'][:200])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(280), np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);\n",
    "plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attr = np.mean(np.sum(full_attrs_G_train, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_attr, diag, '.');\n",
    "plt.xlabel('total attribution');\n",
    "plt.ylabel('mean self attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, total_attr, '.');\n",
    "plt.xlabel('mean expression');\n",
    "plt.ylabel('total attribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_test[keep]), axis=0)\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_norm = full_attrs_G / np.expand_dims(np.sum(full_attrs_G, axis=-1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train_norm = full_attrs_G_norm[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train_norm.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_train_norm[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]\n",
    "\n",
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = full_attrs_G_r[10, :, :140]\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(full_attrs_G, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(test_input_tensor) - model(torch.zeros_like(test_input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(X[:, :100].detach().numpy() - np.sum(full_attrs_G, axis=-1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.zeros_like(test_input_tensor)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model(torch.zeros_like(test_input_tensor))[0].detach().numpy(), bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = np.cumsum(np.mean(np.abs(full_attrs), axis=(0, 2)))\n",
    "fa = fa / fa[-1]\n",
    "\n",
    "plt.plot(np.arange(256), fa);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('cumulative mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[:256, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlm.fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.utils import score_predictions, plot_expression_and_correlation, plot_marker_gene_heatmap\n",
    "\n",
    "\n",
    "adata_test, results = score_predictions(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_expression_and_correlation(adata_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "marker_genes = adata_test.var[adata_test.var['highly_variable']]['feature_name'].values\n",
    "np.random.seed(42)\n",
    "marker_genes = np.random.choice(marker_genes, 50)\n",
    "\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = adata_test.obs.set_index('label').to_dict()['marker_feature_name']\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c78ef6e1dc348573331f887aa1706c62aacac0373dba7ce1cc27999251039c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
