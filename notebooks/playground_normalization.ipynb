{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "from rosa.preprocessing import (\n",
    "    clean_cells_genes,\n",
    ")\n",
    "\n",
    "RAW_ADATA_PT = \"/Users/nsofroniew/Documents/data/multiomics/cell_census/tabula_sapiens_by_features.h5ad\"\n",
    "EMBEDS_ADATA_PT = \"/Users/nsofroniew/Documents/data/multiomics/cell_census/tabula_sapiens_by_features_with_embeds_new_norm.h5ad\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(EMBEDS_ADATA_PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts'].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts_normalized'] = adata.layers['counts'].copy()\n",
    "sc.pp.normalize_total(adata, target_sum=1e5, layer='counts_normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.layers['counts_normalized'].flatten());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.preprocessing import bin_expression, reconstruct_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_expression(adata, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_expression(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((adata.X - adata.layers['reconstructed'])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plt.hist((adata.layers['reconstructed'] - adata.X).ravel(), bins=1000);\n",
    "plt.xlim([-.25, .25]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify cells and genes not trained on (when possible)\n",
    "adata.layers['prediction'] = adata.layers['reconstructed']\n",
    "test_genes = np.logical_not(adata.var[\"train\"])\n",
    "test_cells = np.logical_not(adata.obs[\"train\"])\n",
    "adata_test = adata[test_cells, test_genes]\n",
    "sc.tl.dendrogram(adata_test, groupby=\"label\", use_rep=\"X\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.plotting import plot_marker_gene_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = adata_test.obs.set_index('label').to_dict()['marker_feature_name']\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.layers['binned'].flatten(), bins=25, density=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.X.flatten(), bins=250, density=True);\n",
    "plt.ylim([0, 1]);\n",
    "plt.xlim([0, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((10, 0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class EmbeddingType(Enum):\n",
    "    JOINT = auto()\n",
    "    VAR = auto()\n",
    "    OBS = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingType.JOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(EmbeddingType.__members__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = np.ceil(adata.X)\n",
    "sc.pp.filter_genes(adata, min_cells=1)\n",
    "sc.experimental.pp.normalize_pearson_residuals(adata)\n",
    "adata.X[adata.X<0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isinf(adata.X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(adata.X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.log1p(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X = np.ceil(adata.X)\n",
    "adata.layers[\"counts\"] = adata.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_genes(adata, min_cells=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.filter_cells(adata, min_genes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.layers['counts'].sum(axis=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.layers['counts'].sum(axis=1).mean() / 1e5)\n",
    "print(adata.layers['counts'].sum(axis=1).var() / 1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers[\"counts_normalized_total\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata, 1e5, layer=\"counts_normalized_total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.layers['counts_normalized_total'].sum(axis=1).mean() / 1e5)\n",
    "print(adata.layers['counts_normalized_total'].sum(axis=1).var() / 1e10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers[\"counts_normalized_pearson\"] = adata.X.copy()\n",
    "adata.layers['counts_normalized_pearson'] = np.ceil(adata.layers['counts_normalized_pearson'])\n",
    "sc.experimental.pp.normalize_pearson_residuals(adata, layer=\"counts_normalized_pearson\", theta=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(adata.layers['counts_normalized_pearson']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata.layers['counts_normalized_pearson'].sum(axis=1).mean())\n",
    "print(adata.layers['counts_normalized_pearson'].sum(axis=1).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.layers['counts_normalized_pearson'].flatten(), np.linspace(0, 100, 1000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(adata.layers['counts'].flatten(), np.linspace(0, 100, 1000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log1p(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(adata.layers['counts_normalized_pearson'] - adata.layers['counts']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts_normalized_pearson'] = np.round(adata.layers['counts_normalized_pearson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(adata.layers['counts_normalized_pearson'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.layers['counts_normalized_pearson'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['pearson_residuals_normalization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABULA_SAPIENS_BY_CELL_TYPE_WITH_EMBEDS_PT = \"/Users/nsofroniew/Documents/data/multiomics/cell_census/tabula_sapiens_by_features_with_embeds_new_norm.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_norm = ad.read_h5ad(TABULA_SAPIENS_BY_CELL_TYPE_WITH_EMBEDS_PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.exp(adata_norm.X) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_norm.X = adata_norm.layers['counts'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata_norm, 1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(abs(adata_norm.X - y)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.special import kl_div\n",
    "\n",
    "# y_hat = np.asarray(adata[keep_cells].X.flatten())\n",
    "# y = np.asarray(adata[keep_cells].layers['prediction'].flatten())\n",
    "\n",
    "# kl_div(y, y_hat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest, poisson\n",
    "\n",
    "y_hat = np.asarray(adata[keep_cells].X.flatten())\n",
    "y = np.asarray(adata[keep_cells].layers['prediction'].flatten())\n",
    "\n",
    "kstest(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kstest(y, 'poisson', args=(np.mean(y),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest, poisson\n",
    "\n",
    "poisson_dist = poisson(np.mean(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = poisson_dist.rvs(size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, _ = np.histogram(y, bins=bins)\n",
    "hist_hat, _ = np.histogram(y_hat, bins=bins)\n",
    "plt.bar(bins[:-1], hist/hist.sum(), width=10/1000)\n",
    "plt.bar(bins[:-1], hist_hat/hist_hat.sum(), alpha=0.5, width=10/1000)\n",
    "plt.ylim([0, 1e-2]);\n",
    "plt.xlim([0, 8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson_dist = poisson(np.mean(y))\n",
    "y_new = poisson_dist.rvs(size=10000)\n",
    "\n",
    "\n",
    "hist, _ = np.histogram(y, bins=bins)\n",
    "hist_new, _ = np.histogram(y_new, bins=bins)\n",
    "plt.bar(bins[:-1], hist/hist.sum(), width=10/1000)\n",
    "plt.bar(bins[:-1], hist_new//hist_new.sum(), alpha=0.5, width=10/1000)\n",
    "plt.ylim([0, 1e-2]);\n",
    "plt.xlim([0, 8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = [.2, 0.1, 1.2, 0.0.001]\n",
    "\n",
    "result = minimize(negative_binomial, initial_params, args=(y,), method='Nelder-Mead')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the optimal parameters\n",
    "r1, p1, r2, p2 = result.x\n",
    "data = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import nbinom\n",
    "\n",
    "r1, p1, r2, p2 = (0.1, 0.1, 1.1, 0.1)\n",
    "\n",
    "# nbinom_dist_1 = nbinom(9.1, 0.6)\n",
    "# nbinom_dist_2 = nbinom(1.2, .001)\n",
    "y_new = (nbinom.rvs(.2, 0.1, size=10000) + nbinom.rvs(1.2, 0.001, size=10000)) / 1000\n",
    "\n",
    "\n",
    "hist, _ = np.histogram(y, bins=bins)\n",
    "hist_new, _ = np.histogram(y_new, bins=bins)\n",
    "plt.bar(bins[:-1], hist/hist.sum(), width=10/1000)\n",
    "plt.bar(bins[:-1], hist_new/hist_new.sum(), alpha=0.5, width=10/1000)\n",
    "plt.ylim([0, 1e-2]);\n",
    "plt.xlim([0, 8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import nbinom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample data\n",
    "data = y\n",
    "\n",
    "# Define the negative binomial function\n",
    "def negative_binomial(params, data):\n",
    "    r1, p1, r2, p2 = params\n",
    "    pmf1 = nbinom.pmf(1000 * data, r1, p1)\n",
    "    pmf2 = nbinom.pmf(1000 * data, r2, p2)\n",
    "    return -np.log(pmf1 + pmf2).sum()\n",
    "\n",
    "# Define the initial values for the parameters\n",
    "initial_params = (0.1, 0.1, 1.1, 0.1)\n",
    "\n",
    "\n",
    "# Minimize the negative binomial function using the Nelder-Mead algorithm\n",
    "result = minimize(negative_binomial, initial_params, args=(data,), method='Nelder-Mead')\n",
    "\n",
    "# Extract the optimal parameters\n",
    "r1, p1, r2, p2 = result.x\n",
    "\n",
    "# Plot the histogram of the data\n",
    "plt.hist(data, bins=30, density=True, alpha=0.5, label='Data')\n",
    "\n",
    "# Plot the sum of the negative binomials\n",
    "x = np.arange(0, data.max())\n",
    "pmf1 = nbinom.pmf(x, r1, p1)\n",
    "pmf2 = nbinom.pmf(x, r2, p2)\n",
    "plt.plot(x, pmf1 + pmf2, 'r-', lw=2, label='Sum of Negative Binomials')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  print(x)\n",
    "except NameError:\n",
    "  print(\"Variable x is not defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(2.3).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.varm['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(adata.varm['embedding'].ravel(), bins=2000);\n",
    "plt.xlim([-0.5, 0.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.varm['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit pca on training data\n",
    "pca = PCA()\n",
    "pca.fit(adata.varm['embedding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = pca.transform(adata.varm['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_));\n",
    "plt.xlim([0, 3042])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(pca.explained_variance_ratio_)[512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(E[:, :512].ravel(), bins=2000);\n",
    "plt.xlim([-1.5, 1.5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import anndata as ad\n",
    "from rosa.preprocessing import (\n",
    "    calculate_gene_embeddings_pca,\n",
    ")\n",
    "\n",
    "\n",
    "EMBEDS_ADATA_PT = \"/Users/nsofroniew/Documents/data/multiomics/cell_census/tabula_sapiens_by_features_with_embeds_new_norm.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(EMBEDS_ADATA_PT)\n",
    "adata = calculate_gene_embeddings_pca(adata, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'explained_variance': 0.918266625236611}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.uns[\"embedding_pca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_h5ad(EMBEDS_ADATA_PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.varm['embedding_pca'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.varm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADATA_BULK_PT = \"/Users/nsofroniew/Documents/data/multiomics/cell_census/tabula_sapiens_pbulk.h5ad\"\n",
    "adata = ad.read_h5ad(ADATA_BULK_PT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soma_joinid</th>\n",
       "      <th>feature_name</th>\n",
       "      <th>feature_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000121410</th>\n",
       "      <td>0</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>3999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000268895</th>\n",
       "      <td>1</td>\n",
       "      <td>A1BG-AS1</td>\n",
       "      <td>3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000118017</th>\n",
       "      <td>10</td>\n",
       "      <td>A4GNT</td>\n",
       "      <td>1779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000129968</th>\n",
       "      <td>100</td>\n",
       "      <td>ABHD17A</td>\n",
       "      <td>6163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000236469</th>\n",
       "      <td>1000</td>\n",
       "      <td>AC007040.8</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000256789</th>\n",
       "      <td>9995</td>\n",
       "      <td>RP11-697H9.2</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000255015</th>\n",
       "      <td>9996</td>\n",
       "      <td>RP11-716H6.1</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000255219</th>\n",
       "      <td>9997</td>\n",
       "      <td>RP11-716H6.2</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000255183</th>\n",
       "      <td>9998</td>\n",
       "      <td>LINC02711</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000254528</th>\n",
       "      <td>9999</td>\n",
       "      <td>RP11-728F11.4</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57030 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 soma_joinid   feature_name  feature_length\n",
       "feature_id                                                 \n",
       "ENSG00000121410            0           A1BG            3999\n",
       "ENSG00000268895            1       A1BG-AS1            3374\n",
       "ENSG00000118017           10          A4GNT            1779\n",
       "ENSG00000129968          100        ABHD17A            6163\n",
       "ENSG00000236469         1000     AC007040.8             570\n",
       "...                      ...            ...             ...\n",
       "ENSG00000256789         9995   RP11-697H9.2             423\n",
       "ENSG00000255015         9996   RP11-716H6.1             507\n",
       "ENSG00000255219         9997   RP11-716H6.2             571\n",
       "ENSG00000255183         9998      LINC02711             679\n",
       "ENSG00000254528         9999  RP11-728F11.4            1464\n",
       "\n",
       "[57030 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.var.set_index(\"feature_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pt = '/home/ec2-user/enformer/Homo_sapiens.GRCh38.genes.enformer_embeddings'\n",
    "var_id = 'ENSG00000280445'\n",
    "full_pt = f'{base_pt}/{var_id}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    var = torch.load(full_pt, map_location='cpu')['embedding']\n",
    "    var = torch.from_numpy(var).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "896 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 896, 3072])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = var.unsqueeze(0).unsqueeze(-3)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = torch.nn.Conv2d(1, 10, (896, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30720])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc(a).view(a.shape[0], -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view(a.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ToTensor(torch.nn.Module):\n",
    "    \"\"\"Convert ``numpy.ndarray`` to tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self, dtype: torch.dtype = torch.float32) -> None:\n",
    "        super().__init__()\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(self, tensor: np.ndarray) -> torch.Tensor:\n",
    "        return torch.from_numpy(tensor).type(torch.float32)\n",
    "\n",
    "class CountNormalize(torch.nn.Module):\n",
    "    \"\"\"Normalize a tensor to a fixed total counts.\n",
    "    \"\"\"\n",
    "    def __init__(self, total_counts=1):\n",
    "        super().__init__()\n",
    "        self.total_counts = total_counts\n",
    "\n",
    "    def forward(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return self.total_counts * F.normalize(tensor, p=1.0, eps=1e-12)\n",
    "\n",
    "\n",
    "class Log1p(torch.nn.Module):\n",
    "    \"\"\"Log1p normalize a tensor.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.log1p(tensor)\n",
    "\n",
    "\n",
    "class QuantileNormalize(torch.nn.Module):\n",
    "    \"\"\"Normalize a tensor by quantiles.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins):\n",
    "        super().__init__()\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def forward(self, tensor: torch.Tensor) -> torch.Tensor:\n",
    "        boundaries = torch.quantile(tensor, torch.linspace(0, 1, self.n_bins))\n",
    "        return torch.bucketize(tensor, boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionTransform(torch.nn.Sequential):\n",
    "    def __init__(self, cfg):\n",
    "        # Add base transform\n",
    "        transforms = [ToTensor()]\n",
    "\n",
    "        if cfg.total_counts is not None:\n",
    "            transforms.append(CountNormalize(cfg.total_counts))\n",
    "\n",
    "        if cfg.log1p:\n",
    "            transforms.append(Log1p())\n",
    "\n",
    "        if cfg.n_bins is not None:\n",
    "            transforms.append(QuantileNormalize(cfg.n_bins))\n",
    "\n",
    "        super().__init__(*transforms)\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExpressionTransformConfig:\n",
    "    total_counts: Optional[int] = None\n",
    "    log1p: Optional[bool] = None\n",
    "    n_bins: Optional[int] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_cfg = ExpressionTransformConfig(n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = ExpressionTransform(exp_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3, 1])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantile(ToTensor()(X).unsqueeze(0), torch.linspace(0, 1, 5), dim=-1, keepdim=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 30])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ToTensor()(X).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5, 1, 5, 9, 7, 2, 0, 1, 2, 7, 6, 9, 4, 9, 6, 3, 8, 8])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf(np.random.rand(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.Sequential(ToTensor(), CountNormalize(10), Log1p(), QuantileNormalize(10))\n",
    "b = torch.nn.Sequential(ToTensor(), QuantileNormalize(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(3, 30)\n",
    "X [0, :3] = 0\n",
    "X [0, :] = X [0, :] * 1000\n",
    "# X = torch.randint(1, 5, size=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.04933046e+02,\n",
       "        5.86185246e+02, 3.67209684e+02, 9.28032463e+02, 9.43061788e+02,\n",
       "        6.61347813e+02, 9.09201383e+02, 6.52564336e+01, 7.99837338e+02,\n",
       "        2.61558041e+02, 7.52127084e+02, 9.60963693e+02, 3.92288179e+02,\n",
       "        8.56678094e+02, 6.97483553e+02, 1.11283442e+02, 7.34695066e+02,\n",
       "        8.55954620e+02, 8.99893485e+02, 2.86306631e+02, 1.61621586e+02,\n",
       "        3.46326170e+02, 6.44120733e+02, 9.49631103e+02, 4.06631873e+00,\n",
       "        9.37364444e+02, 9.67401543e+02],\n",
       "       [2.60777832e-01, 9.44569420e-01, 9.31749530e-01, 1.39988490e-01,\n",
       "        5.88439432e-01, 8.94237201e-01, 2.34748228e-01, 1.43530256e-01,\n",
       "        5.14576896e-01, 1.99584205e-01, 5.56390586e-01, 3.41238556e-01,\n",
       "        6.24677666e-01, 4.59784231e-01, 5.80895454e-01, 4.41532664e-01,\n",
       "        5.67134862e-02, 1.51184503e-01, 7.05252488e-01, 6.01157209e-01,\n",
       "        9.84628333e-01, 4.45089557e-01, 2.13056719e-01, 4.27250153e-01,\n",
       "        6.44899373e-01, 2.14565691e-01, 2.20508775e-01, 9.98951048e-02,\n",
       "        9.41615457e-01, 6.41620978e-01],\n",
       "       [8.94089945e-01, 1.12421102e-01, 9.11242744e-01, 5.36732599e-01,\n",
       "        7.66255925e-01, 4.53289727e-01, 9.51083579e-01, 3.75815038e-01,\n",
       "        5.23343990e-01, 8.27400068e-01, 2.82642832e-01, 5.81115355e-01,\n",
       "        5.37591246e-01, 1.85946015e-01, 1.12525304e-01, 3.25400331e-01,\n",
       "        7.10503208e-01, 6.21157848e-01, 2.73205471e-01, 5.35723475e-01,\n",
       "        4.09939801e-01, 7.92092881e-01, 8.55056225e-01, 6.73185017e-01,\n",
       "        6.72154957e-01, 2.06790547e-01, 3.03884416e-01, 1.17774024e-01,\n",
       "        3.79656400e-01, 5.36711374e-01]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 4, 3, 6, 7, 8, 6, 3, 5, 1, 5, 9, 8, 7, 2, 9, 2, 2, 6, 5, 4, 7,\n",
       "         8, 5, 4, 2, 9, 9],\n",
       "        [7, 6, 2, 1, 5, 1, 4, 4, 6, 5, 8, 6, 7, 9, 9, 3, 3, 5, 1, 1, 5, 8, 3, 9,\n",
       "         9, 3, 3, 2, 6, 9],\n",
       "        [7, 2, 1, 4, 8, 4, 3, 8, 2, 7, 2, 6, 9, 7, 8, 7, 5, 6, 4, 5, 8, 3, 8, 6,\n",
       "         1, 2, 7, 3, 4, 4]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 4, 3, 6, 6, 8, 5, 3, 5, 1, 5, 8, 7, 7, 2, 9, 2, 2, 6, 5, 4, 7,\n",
       "         8, 5, 4, 2, 8, 9],\n",
       "        [7, 6, 2, 1, 5, 1, 4, 4, 6, 6, 8, 6, 8, 9, 9, 3, 3, 5, 1, 1, 5, 8, 3, 9,\n",
       "         9, 3, 3, 2, 6, 9],\n",
       "        [7, 2, 1, 4, 9, 4, 3, 8, 2, 7, 2, 6, 9, 7, 9, 7, 5, 7, 4, 5, 8, 3, 8, 6,\n",
       "         1, 2, 7, 3, 4, 4]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([146, 150, 151])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(X).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.24"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 * 512 / 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.dtype"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
