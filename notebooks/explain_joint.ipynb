{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n",
      "/var/folders/6n/b_zkz2ns3_l02s3g4lnlklxr0000gq/T/ipykernel_15318/4235644688.py:13: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir=config_dir):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RosaLightningModule(\n",
      "  (model): RosaJointModel(\n",
      "    (main): Sequential(\n",
      "      (dual_embed): ParallelEmbed(\n",
      "        (models): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (layer_norm_0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (input_embed_0): Identity()\n",
      "          )\n",
      "          (1): Sequential(\n",
      "            (layer_norm_1): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
      "            (input_embed_1): InputEmbed(\n",
      "              (model): Sequential(\n",
      "                (projection): Linear(in_features=3072, out_features=256, bias=True)\n",
      "                (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.5, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (join_embeds): DotEmbeds()\n",
      "      (feed_forward): Identity()\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "      (expression_head): ProjectionExpressionHead(\n",
      "        (model): Sequential(\n",
      "          (projection): Identity()\n",
      "          (activation): Softplus(beta=1, threshold=20)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from glob import  glob\n",
    "# from rosa import  predict\n",
    "from rosa.data import create_io_paths, RosaDataModule\n",
    "from rosa.modeling.modules import RosaLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/nsofroniew/Documents/data/rosa/outputs/2023-02-13/11-35-55\"\n",
    "config_dir = BASE_DIR + \"/.hydra\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_dir):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=OmegaConf.load(config_dir + \"/overrides.yaml\"))\n",
    "\n",
    "    chkpts = BASE_DIR + \"/checkpoints/*.ckpt\"\n",
    "    chkpt = glob(chkpts)[1]\n",
    "\n",
    "    _, output_path = create_io_paths(config.paths)\n",
    "\n",
    "    # Create Data Module\n",
    "    rdm = RosaDataModule(\n",
    "        output_path,\n",
    "        config=config.data_module,\n",
    "    )\n",
    "    rdm.setup()\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    rlm = RosaLightningModule.load_from_checkpoint(\n",
    "        chkpt,\n",
    "        in_dim=rdm.len_input,\n",
    "        out_dim=rdm.len_target,\n",
    "        config=config.module,\n",
    "    )\n",
    "    print(rlm)\n",
    "\n",
    "    # trainer = Trainer()\n",
    "    # predictions = trainer.predict(rlm, rdm)\n",
    "    # rdm.predict_dataset.predict(predictions)\n",
    "    # adata = rdm.predict_dataset.adata\n",
    "    # adata = predict(config, chkpt)\n",
    "\n",
    "# display(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from captum.attr import IntegratedGradients, InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = rdm.predict_dataset.adata\n",
    "test_obs = np.logical_not(adata.obs['train'])\n",
    "test_var = np.logical_not(adata.var['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, rlm):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.model = rlm.model\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return self.model((x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel(rlm)\n",
    "ixg = InputXGradient(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(rdm.predict_dataloader(batch_size=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(*x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_r = tuple(x_ind.reshape(-1, x_ind.shape[-1]).requires_grad_() for x_ind in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19431, 3072])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_r[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_r = ixg.attribute(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribution = tuple(a.reshape(x[0].shape[0], x[0].shape[1], -1) for a in attribution_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431, 3072])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribution[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = next(iter(rlm.explain_iter(rdm.predict_dataloader(batch_size=1), ixg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431, 256])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [02:57,  1.68it/s]"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "# results_shape = tuple((len(rdm.predict_dataset), rdm.len_target, r) for r in rdm.len_input) # rdm.len_target\n",
    "results_shape = tuple(rdm.predict_dataset.adata.shape + (r,) for r in rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = tuple(zarr.open(f'data/joint_attribution{i}.zarr', mode='w', shape=r, chunks=(1, None, None), dtype=np.float32) for i, r in enumerate(results_shape))\n",
    "\n",
    "ind = 0\n",
    "dl = rdm.predict_dataloader(batch_size=1)\n",
    "for attribution in tqdm(iter(rlm.explain_iter(dl, ixg)), total=len(dl)):\n",
    "    for i, a in enumerate(attribution):\n",
    "        z[i][ind:ind+len(a), :, :] = a.detach().numpy() # for joint\n",
    "    ind += len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/369 [00:08<02:59,  1.97it/s]"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "# results_shape = tuple((len(rdm.predict_dataset), rdm.len_target, r) for r in rdm.len_input) # rdm.len_target\n",
    "results_shape = tuple(rdm.predict_dataset.adata.shape + (r,) for r in rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "# z = tuple(zarr.open(f'data/joint_attribution{i}.zarr', mode='w', shape=r, chunks=(1, None, None), dtype=np.float32) for i, r in enumerate(results_shape))\n",
    "\n",
    "ind = 0\n",
    "for x, y in tqdm(iter(rdm.predict_dataloader(batch_size=1))):\n",
    "    x_r = tuple(x_ind.reshape(-1, x_ind.shape[-1]).requires_grad_() for x_ind in x)\n",
    "    attribution_r = ixg.attribute(x_r)\n",
    "    attribution = tuple(a.reshape(x[0].shape[0], x[0].shape[1], -1) for a in attribution_r)\n",
    "    for i, a in enumerate(attribution):\n",
    "        pass\n",
    "        # z[target, ind:ind+len(x), :] = attribution # for gene dataset\n",
    "        # z[i][ind:ind+len(a), :, :] = a.detach().numpy() # for cell dataset\n",
    "        #### for joint have to do something more clever ...... maybe swap iterators\n",
    "    ind += len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "results_shape = (len(rdm.predict_dataset), 50, rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.zeros(results_shape, chunks=(1, None, None), dtype=np.float32)\n",
    "\n",
    "ind = 0\n",
    "for x, y in tqdm(iter(rdm.predict_dataloader(batch_size=1)), leave=False):\n",
    "    for target in tqdm(range(50)):\n",
    "        x.requires_grad_()\n",
    "        attribution = ixg.attribute(x, target=target)\n",
    "        attribution = attribution.detach().numpy()\n",
    "        # z[target, ind:ind+len(x), :] = attribution # for gene dataset\n",
    "        z[ind:ind+len(x), target, :] = attribution # for cell dataset\n",
    "        #### for joint have to do something more clever ...... maybe swap iterators\n",
    "    ind += len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/369 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "attr = next(iter(explain_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431, 3072])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.05it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.10it/s]/s]\n",
      "  9%|▊         | 32/369 [00:16<02:57,  1.90it/s]"
     ]
    }
   ],
   "source": [
    "for attr in iter(explain_iter):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "# results_shape = tuple((len(rdm.predict_dataset), rdm.len_target, r) for r in rdm.len_input) # rdm.len_target\n",
    "results_shape = tuple(rdm.predict_dataset.adata.shape + (r,) for r in rdm.len_input) # rdm.len_target\n",
    "\n",
    "z = tuple(zarr.open(f'data/joint_attribution{i}.zarr', mode='r', shape=r, chunks=(1, None, None), dtype=np.float32) for i, r in enumerate(results_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "# results_shape = tuple((len(rdm.predict_dataset), rdm.len_target, r) for r in rdm.len_input) # rdm.len_target\n",
    "results_shape = tuple(rdm.predict_dataset.adata.shape + (r,) for r in rdm.len_input) # rdm.len_target\n",
    "\n",
    "z = tuple(da.from_zarr(f'data/joint_attribution{i}.zarr') for i, r in enumerate(results_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(z[1]), axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_avg = tuple(np.asarray(da.abs(z_i).mean(axis=(0, 1))) for z_i in z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(z_avg[0])), z_avg[0]);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(len(z_avg[1])), np.sort(z_avg[1])[::-1]);\n",
    "plt.xlabel('embed dim');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(z_avg[1])\n",
    "z = (z[0], z[1][:, :, indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tuple(np.asarray(z_ind[:, :, :50]) for z_ind in z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.zeros((z[0].shape[2], z[1].shape[2]))\n",
    "\n",
    "for t in tqdm(range(z[0].shape[2])):\n",
    "    for s in tqdm(range(z[1].shape[2])):\n",
    "        C[t, s] = np.corrcoef(z[0][test_obs][:, test_var, t].flatten(), z[1][test_obs][:, test_var, s].flatten())[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "train_cells = adata.obs['train']\n",
    "train_genes = adata.var['train']\n",
    "adata_split = adata[train_cells, train_genes]\n",
    "\n",
    "# fit pca on training data\n",
    "pca = PCA()\n",
    "pca.fit(adata_split.X)\n",
    "\n",
    "# compute scores for all cells\n",
    "pca_expression = pca.transform(adata[:, train_genes].X)\n",
    "\n",
    "# # add cell embeddings to obsm\n",
    "# n_pcs = config.pcs\n",
    "# n_pcs = min(n_pcs, pca_expression.shape[1] - 1)\n",
    "# adata.obsm[\"embedding\"] = pca_expression[:, :n_pcs]\n",
    "# adata.uns[\"obs_embedding_pca\"] = {\n",
    "#     \"explained_variance\": np.cumsum(pca.explained_variance_ratio_)[n_pcs]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enformer_pytorch import Enformer\n",
    "\n",
    "\n",
    "MODEL_PT = \"EleutherAI/enformer-official-rough\"\n",
    "SEQ_EMBED_DIM = 896\n",
    "EMBED_DIM = 3072\n",
    "TSS = int(SEQ_EMBED_DIM // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, rlm, pca):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.input_mean = torch.from_numpy(pca.mean_)\n",
    "        self.input_weights = torch.from_numpy(pca.components_[:256])\n",
    "        self.enformer = Enformer.from_pretrained(MODEL_PT, output_heads=dict(), use_checkpointing=False)\n",
    "        self.tss = TSS\n",
    "        self.model = rlm.model\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = x1 - self.input_mean\n",
    "        x1 = torch.einsum('ij, kj -> ik', x1, self.input_weights)\n",
    "        _, x2 = self.enformer(x2, return_embeddings=True)\n",
    "        x2 = x2[:, self.tss]\n",
    "        return self.model((x1, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel(rlm, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.utils import score_predictions, plot_expression_and_correlation, plot_marker_gene_heatmap\n",
    "\n",
    "\n",
    "adata_test, results = score_predictions(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_expression_and_correlation(adata_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "marker_genes = adata_test.var[adata_test.var['highly_variable']]['feature_name'].values\n",
    "np.random.seed(42)\n",
    "marker_genes = np.random.choice(marker_genes, 50)\n",
    "\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = adata_test.obs.set_index('label').to_dict()['marker_feature_name']\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c78ef6e1dc348573331f887aa1706c62aacac0373dba7ce1cc27999251039c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
