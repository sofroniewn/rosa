{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: LightningDeprecationWarning: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      "  new_rank_zero_deprecation(\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: LightningDeprecationWarning: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n",
      "  return new_rank_zero_deprecation(*args, **kwargs)\n",
      "/var/folders/6n/b_zkz2ns3_l02s3g4lnlklxr0000gq/T/ipykernel_13366/309743568.py:13: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir=config_dir):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RosaLightningModule(\n",
      "  (model): RosaSingleModel(\n",
      "    (main): Sequential(\n",
      "      (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (input_embed): Identity()\n",
      "      (feed_forward): Identity()\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (expression_head): ProjectionExpressionHead(\n",
      "        (model): Sequential(\n",
      "          (projection): Linear(in_features=256, out_features=19431, bias=True)\n",
      "          (activation): Softplus(beta=1, threshold=20)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1789: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n",
      "Missing logger folder: /Users/nsofroniew/Documents/GitHub/rosa/notebooks/lightning_logs\n",
      "/Users/nsofroniew/opt/anaconda3/envs/multiomics/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c243dab5004afd93fef4c7c52c4a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 369 × 19431\n",
       "    obs: 'dataset_id', 'cell_type', 'cell_type_ontology_term_id', 'development_stage', 'development_stage_ontology_term_id', 'disease', 'disease_ontology_term_id', 'donor_id', 'is_primary_data', 'self_reported_ethnicity', 'self_reported_ethnicity_ontology_term_id', 'sex', 'sex_ontology_term_id', 'suspension_type', 'label', 'sample', 'n_genes', 'train', 'marker_gene', 'marker_feature_name'\n",
       "    var: 'soma_joinid', 'feature_name', 'feature_length', 'column_1', 'column_2', 'column_3', 'column_4', 'external_gene_name', 'gene_biotype', 'train', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'dendrogram_label', 'hvg', 'log1p', 'obs_embedding_pca', 'preprocessing', 'rank_genes_groups', 'var_embedding_pca'\n",
       "    obsm: 'bin_edges', 'embedding'\n",
       "    varm: 'embedding', 'embedding_pca'\n",
       "    layers: 'binned', 'counts', 'log1p', 'normalized_counts', 'prediction'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from glob import  glob\n",
    "# from rosa import  predict\n",
    "from rosa.data import create_io_paths, RosaDataModule\n",
    "from rosa.modeling.modules import RosaLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "BASE_DIR = \"/Users/nsofroniew/Documents/data/rosa/outputs/2023-02-12/21-57-00\"\n",
    "config_dir = BASE_DIR + \"/.hydra\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_dir):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=OmegaConf.load(config_dir + \"/overrides.yaml\"))\n",
    "\n",
    "    chkpts = BASE_DIR + \"/checkpoints/*.ckpt\"\n",
    "    chkpt = glob(chkpts)[1]\n",
    "\n",
    "    _, output_path = create_io_paths(config.paths)\n",
    "\n",
    "    # Create Data Module\n",
    "    rdm = RosaDataModule(\n",
    "        output_path,\n",
    "        config=config.data_module,\n",
    "    )\n",
    "    rdm.setup()\n",
    "\n",
    "    # Load model from checkpoint\n",
    "    rlm = RosaLightningModule.load_from_checkpoint(\n",
    "        chkpt,\n",
    "        in_dim=rdm.len_input,\n",
    "        out_dim=rdm.len_target,\n",
    "        config=config.module,\n",
    "    )\n",
    "    print(rlm)\n",
    "\n",
    "    trainer = Trainer()\n",
    "    predictions = trainer.predict(rlm, rdm)\n",
    "    rdm.predict_dataset.predict(predictions)\n",
    "    adata = rdm.predict_dataset.adata\n",
    "    # adata = predict(config, chkpt)\n",
    "\n",
    "display(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "train_cells = adata.obs['train']\n",
    "train_genes = adata.var['train']\n",
    "adata_split = adata[train_cells, train_genes]\n",
    "\n",
    "# fit pca on training data\n",
    "pca = PCA()\n",
    "pca.fit(adata_split.X)\n",
    "\n",
    "# compute scores for all cells\n",
    "pca_expression = pca.transform(adata[:, train_genes].X)\n",
    "\n",
    "# # add cell embeddings to obsm\n",
    "# n_pcs = config.pcs\n",
    "# n_pcs = min(n_pcs, pca_expression.shape[1] - 1)\n",
    "# adata.obsm[\"embedding\"] = pca_expression[:, :n_pcs]\n",
    "# adata.uns[\"obs_embedding_pca\"] = {\n",
    "#     \"explained_variance\": np.cumsum(pca.explained_variance_ratio_)[n_pcs]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trans = np.einsum('ij, kj -> ik', adata[:, train_genes].X - pca.mean_, pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from captum library\n",
    "from captum.attr import IntegratedGradients, InputXGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(rlm)\n",
    "ixg = InputXGradient(rlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor = rdm.predict_dataset[:][0]\n",
    "target_tensor = rdm.predict_dataset[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(rdm.predict_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19431"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def make_explain_iter(rdm, explainer, batch_size=1):\n",
    "    if rdm.len_target == 1:\n",
    "        for x, y in iter(rdm.predict_dataloader(batch_size=batch_size)):\n",
    "            x = tuple(x_ind.reshape(-1, x_ind.shape[-1]).requires_grad_() for x_ind in x)\n",
    "            attribution = explainer.attribute(x)\n",
    "            yield tuple(a.reshape(y.shape[0], y.shape[1], -1) for a in attribution)\n",
    "    else:\n",
    "        for x, y in iter(rdm.predict_dataloader(batch_size=batch_size)):\n",
    "            attribution = []\n",
    "            for target in range(rdm.len_target):\n",
    "                x.requires_grad_()\n",
    "                attribution.append(explainer.attribute(x, target=target))\n",
    "            yield torch.stack(attribution, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_iter = make_explain_iter(rdm, ixg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = next(iter(explain_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 19431, 256])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "results_shape = (len(rdm.predict_dataset), rdm.len_target, rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.zeros(results_shape, chunks=(1, None, None), dtype=np.float32)\n",
    "\n",
    "ind = 0\n",
    "for attr in tqdm(iter(explain_iter)):\n",
    "    z[ind:ind+len(attr), :, :] = attr # for cell dataset\n",
    "    # z[:, ind:ind+len(attr), :] = attr # for gene dataset\n",
    "    ind += len(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "results_shape = (len(rdm.predict_dataset), 50, rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.zeros(results_shape, chunks=(1, None, None), dtype=np.float32)\n",
    "\n",
    "ind = 0\n",
    "for x, y in tqdm(iter(rdm.predict_dataloader(batch_size=1)), leave=False):\n",
    "    for target in tqdm(range(50)):\n",
    "        x.requires_grad_()\n",
    "        attribution = ixg.attribute(x, target=target)\n",
    "        attribution = attribution.detach().numpy()\n",
    "        # z[target, ind:ind+len(x), :] = attribution # for gene dataset\n",
    "        z[ind:ind+len(x), target, :] = attribution # for cell dataset\n",
    "        #### for joint have to do something more clever ...... maybe swap iterators\n",
    "    ind += len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "results_shape = (len(rdm.predict_dataset), 50, rdm.len_input) # rdm.len_target\n",
    "# results_shape = rdm.predict_dataset.adata.shape + (rdm.len_input,)\n",
    "z = zarr.zeros(results_shape, chunks=(1, None, None), dtype=np.float32)\n",
    "\n",
    "results = []\n",
    "for x, y in tqdm(iter(rdm.predict_dataloader()), leave=False):\n",
    "    results_batch = []\n",
    "    for target in tqdm(range(50)):\n",
    "        x.requires_grad_()\n",
    "        attribution = ixg.attribute(x, target=target)\n",
    "        attribution = attribution.detach().numpy()\n",
    "        results_batch.append(attribution)\n",
    "    results_batch = np.stack(results_batch, axis=1)\n",
    "    results.append(results_batch)\n",
    "results = np.concatenate(results)\n",
    "\n",
    "# results = results.swapaxes(0, 1)\n",
    "# results = results.swapaxes(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.swapaxes(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cells x genes x cell_embedding - for cell model\n",
    "# cells x genes x gene_embedding - for gene model (right now would be genes x cells - need a transpose)\n",
    "# BOTH for joint model .....\n",
    "\n",
    "# Allow for normal model + modified model.\n",
    "# For modified model for cells include pca .... add pca components to adata `uns` ....?????\n",
    "# For modified model for gene include enformer\n",
    "# For modified model for joint include both\n",
    "\n",
    "# Once have attribution working get TFMolDisco working ....\n",
    "# Explore ground truth / databases ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm.predict_dataset.adata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs = np.asarray(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), full_attrs[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), np.mean(np.abs(full_attrs), axis=(0, 1)));\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_[:full_attrs.shape[2]], np.exp(np.mean(np.abs(full_attrs), axis=(0, 1))), '.');\n",
    "plt.xlabel('singular values');\n",
    "plt.ylabel('mean attribution score');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs.shape[2]), pca.explained_variance_ratio_[:full_attrs.shape[2]]);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('singular values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs), axis=(0,))[:, :85]);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('target gene');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_attrs.shape)\n",
    "print(pca.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.einsum('ijk, kl -> ijl', full_attrs, pca.components_[:256, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(output.shape[2]), np.mean(np.abs(output), axis=(0, 1)));\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(output.shape[2]), np.sort(np.mean(np.abs(output), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_r = output[:, adata.var['train'][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(output_r), axis=0)[:, :70]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(test_input_tensor.detach().numpy()[:, :25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(np.mean(np.abs(full_attrs), axis=0)[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "D = np.mean(np.abs(output_r), axis=0)[:, :70]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, rlm, pca):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.input_mean = torch.from_numpy(pca.mean_)\n",
    "        self.input_weights = torch.from_numpy(pca.components_[:256])\n",
    "        self.model = rlm.model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x - self.input_mean\n",
    "        x = torch.einsum('ij, kj -> ik', x, self.input_weights)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel(rlm, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor = torch.from_numpy(adata[:, train_genes].X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(test_input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ig = IntegratedGradients(model)\n",
    "ig = InputXGradient(model)\n",
    "\n",
    "full_attrs_G = []\n",
    "for targ in tqdm(range(200)):\n",
    "    test_input_tensor.requires_grad_()\n",
    "    attr = ig.attribute(test_input_tensor, target=targ)\n",
    "    attr = attr.detach().numpy()\n",
    "    full_attrs_G.append(attr)\n",
    "full_attrs_G = np.stack(full_attrs_G, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G.shape[2]), np.sort(np.mean(np.abs(full_attrs_G), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train = full_attrs_G[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_test = full_attrs_G[:, np.logical_not(adata.var['train'][:200])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(280), np.mean(np.abs(full_attrs_G_train), axis=(0, 1))[:280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);\n",
    "plt.imshow(np.mean(np.abs(full_attrs_G_train[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_attr = np.mean(np.sum(full_attrs_G_train, axis=-1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_attr, diag, '.');\n",
    "plt.xlabel('total attribution');\n",
    "plt.ylabel('mean self attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vals, total_attr, '.');\n",
    "plt.xlabel('mean expression');\n",
    "plt.ylabel('total attribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_test[keep]), axis=0)\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_norm = full_attrs_G / np.expand_dims(np.sum(full_attrs_G, axis=-1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs_G_train_norm = full_attrs_G_norm[:, adata.var['train'][:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(full_attrs_G_train_norm.shape[2]), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1)))[::-1]);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[:140])[::-1]);\n",
    "plt.bar(np.arange(140), np.sort(np.mean(np.abs(full_attrs_G_train_norm), axis=(0, 1))[140:280])[::-1], alpha=0.5);\n",
    "plt.xlabel('gene');\n",
    "plt.ylabel('mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_train_norm[np.logical_not(adata.obs['train'])]), axis=0)[:, :280]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "keep = np.logical_not(adata.obs['train'])\n",
    "D = np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140]\n",
    "\n",
    "link = linkage(D) # D being the measurement\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = np.diagonal(np.mean(np.abs(full_attrs_G_train_norm[keep]), axis=0)[:, :140])\n",
    "vals = np.mean(adata[:, train_genes].X, axis=0)[:140]\n",
    "\n",
    "plt.plot(vals, diag, '.');\n",
    "plt.xlabel('mean expression')\n",
    "plt.ylabel('mean self attribution score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = full_attrs_G_r[10, :, :140]\n",
    "sns.clustermap(D, row_linkage=link, col_linkage=link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.mean(np.abs(full_attrs_G_t), axis=0)[:, :140]\n",
    "sns.clustermap(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(full_attrs_G, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model(test_input_tensor) - model(torch.zeros_like(test_input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(X[:, :100].detach().numpy() - np.sum(full_attrs_G, axis=-1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.zeros_like(test_input_tensor)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model(torch.zeros_like(test_input_tensor))[0].detach().numpy(), bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = np.cumsum(np.mean(np.abs(full_attrs), axis=(0, 2)))\n",
    "fa = fa / fa[-1]\n",
    "\n",
    "plt.plot(np.arange(256), fa);\n",
    "plt.xlabel('n PC');\n",
    "plt.ylabel('cumulative mean attribution score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[:256, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlm.fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosa.utils import score_predictions, plot_expression_and_correlation, plot_marker_gene_heatmap\n",
    "\n",
    "\n",
    "adata_test, results = score_predictions(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_expression_and_correlation(adata_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "marker_genes = adata_test.var[adata_test.var['highly_variable']]['feature_name'].values\n",
    "np.random.seed(42)\n",
    "marker_genes = np.random.choice(marker_genes, 50)\n",
    "\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_genes_dict = adata_test.obs.set_index('label').to_dict()['marker_feature_name']\n",
    "plot_marker_gene_heatmap(adata_test, marker_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c78ef6e1dc348573331f887aa1706c62aacac0373dba7ce1cc27999251039c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
